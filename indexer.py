import pyrogram
import sqlite3
import time
import asyncio
from config import API_ID, API_HASH, SOURCE_CHANNEL, OPENAI_API_KEY # ุงุณุชูุฑุงุฏ ุงูููุงุชูุญ

# ุฅุนุฏุงุฏ ูุงุนุฏุฉ ุงูุจูุงูุงุช
DB_NAME = "books_index.db"
conn = sqlite3.connect(DB_NAME)
cursor = conn.cursor()

# ุฅูุดุงุก ุฌุฏูู ุงูููุฑุณ ุฅุฐุง ูู ููู ููุฌูุฏุงู
cursor.execute("""
    CREATE TABLE IF NOT EXISTS books (
        id INTEGER PRIMARY KEY,
        message_id INTEGER UNIQUE,
        title TEXT,
        author TEXT,
        file_id TEXT,
        publish_date TEXT
    )
""")
conn.commit()

# ุชููุฆุฉ ุนููู Pyrogram
app = pyrogram.Client(
    "indexer_session", 
    api_id=API_ID, 
    api_hash=API_HASH
)

# ===================================================
# ุฏุงูุฉ ุงูุชุญููู ุงูุฐูู ุจุงุณุชุฎุฏุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู (AI Parsing)
# *ูุฐู ุงูุฏุงูุฉ ุชุณุชุฎุฏู ููุชุงุญ OpenAI ุงูุฎุงุต ุจู ูุชุญููู ุงููุต ุงููุนูุฏ*
# ===================================================
def intelligent_parse(raw_text):
    """
    ูุณุชุฎุฏู ุงูุฐูุงุก ุงูุงุตุทูุงุนู (GPT) ูุงุณุชุฎูุงุต ุงูุนููุงู ูุงููุคูู ุจุฏูุฉ ุนุงููุฉ 
    ูู ูุต ุงูุฑุณุงูุฉ ุบูุฑ ุงูููุธู. 
    """
    import openai 
    openai.api_key = OPENAI_API_KEY

    prompt = f"""
    ุฃูุช ูุญูู ุจูุงูุงุช ุฐูู. ุญูู ุงููุต ุงูุชุงูู ูุงุณุชุฎุฑุฌ ููู ุจุฏูุฉ:
    1. ุงูุนููุงู ุงููุงูู ูููุชุงุจ (title).
    2. ุงุณู ุงููุคูู (author).
    
    ุงูุฑุฏ ูุฌุจ ุฃู ูููู ุจุตูุบุฉ JSON ููุท. ุฅุฐุง ูู ุชุฌุฏ ุงูุนููุงูุ ุงุณุชุฎุฏู "ุนููุงู ุบูุฑ ูุนุฑูู".
    
    ุงููุต: "{raw_text[:1000]}"
    """ # ูุชู ุงูุชุทุงุน ุงููุต ุงูุทููู ูุญูุงูุฉ ุงูู API Limit
    
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a data extraction expert. Extract the book title and author as a JSON object: {'title': '...', 'author': '...'}. Reply ONLY with the JSON."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            max_tokens=150
        )
        
        # ุชุญููู ุงุณุชุฌุงุจุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู
        import json
        ai_data = json.loads(response.choices[0].message.content)
        return ai_data

    except Exception as e:
        print(f"โ๏ธ ุฎุทุฃ ูู ุชุญููู AI: {e}")
        return {"title": "ุนููุงู ุบูุฑ ูุนุฑูู", "author": "ูุคูู ุบูุฑ ูุนุฑูู"}


# ========== ุฏุงูุฉ ุงูููุฑุณุฉ ุงูุฑุฆูุณูุฉ ==========
async def start_indexing():
    await app.start()
    print("โ ุชู ุงูุงุชุตุงู ุจุญุณุงุจู. ุจุฏุก ุนูููุฉ ููุฑุณุฉ ููุงุฉ @lovekotob...")

    last_message_id = 0
    total_indexed = 0

    while True:
        try:
            # ุฌูุจ ุงูุฑุณุงุฆู ุนูู ุฏูุนุงุช (ุฏูุนุฉ ุจุญุฏ ุฃูุตู 100 ุฑุณุงูุฉ)
            messages = await app.get_history(
                SOURCE_CHANNEL, 
                limit=100, 
                offset_id=last_message_id
            )
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุฌูุจ ุณุฌู ุงูุฑุณุงุฆู: {e}")
            break

        if not messages:
            break

        for message in messages:
            # ูุชุฃูุฏ ูู ุฃู ุงูุฑุณุงูุฉ ููู (ูุชุงุจ) ูููุง ูุต
            if message.document and (message.caption or message.text):
                
                raw_text = message.caption or message.text
                
                # ุงุณุชุฎุฏุงู ุงูุชุญููู ุงูุฐูู (AI) ูุงุณุชุฎูุงุต ุงูุจูุงูุงุช
                extracted_data = intelligent_parse(raw_text)
                
                extracted_title = extracted_data.get("title", "ุนููุงู ุบูุฑ ูุนุฑูู")
                extracted_author = extracted_data.get("author", "ูุคูู ุบูุฑ ูุนุฑูู")
                
                if extracted_title != "ุนููุงู ุบูุฑ ูุนุฑูู":
                    try:
                        cursor.execute("""
                            INSERT OR IGNORE INTO books 
                            (message_id, title, author, file_id, publish_date)
                            VALUES (?, ?, ?, ?, ?)
                        """, (
                            message.id,
                            extracted_title,
                            extracted_author,
                            message.document.file_id, 
                            str(message.date)
                        ))
                        total_indexed += 1
                    except Exception as e:
                        print(f"โ๏ธ ุฎุทุฃ ูู ุญูุธ ุงูุฑุณุงูุฉ {message.id} ูู DB: {e}")
            
            last_message_id = message.id # ุชุญุฏูุซ ูุขุฎุฑ ุฑุณุงูุฉ ุชูุช ูุนุงูุฌุชูุง

        conn.commit()
        print(f"ุชู ููุฑุณุฉ ุฏูุนุฉ ุฌุฏูุฏุฉ. ุฅุฌูุงูู ุงููุชุจ ุงููููุฑุณุฉ: {total_indexed}. ุขุฎุฑ ูุนุฑูู ุฑุณุงูุฉ: {last_message_id}")
        # ุงูุชุธุงุฑ ูุตูุฑ ูุชุฌูุจ ูููุฏ ุชููุฌุฑุงู
        time.sleep(1.5) 

    print("๐ ุงูุชููุช ุนูููุฉ ููุฑุณุฉ ุงูููุงุฉ ุจุงููุงูู!")
    await app.stop()
    conn.close()

# ุชุดุบูู ุงูุฏุงูุฉ
if __name__ == "__main__":
    asyncio.run(start_indexing())
    
